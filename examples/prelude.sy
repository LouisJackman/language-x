package sylan.lang
/**
 * This is the proposed prelude file, which serves as an example of what Sylan
 * should look like and also shows what utilities are available everywhere.
 *
 * This is similar in spirit to Java's `java.lang` package or Haskell's
 * standard prelude. Eventually it should also expose built-ins via
 * declarations without bodies, once the mechanics of that have been worked out.
 *
 * For now, we just `extend` existing built-in and types and mark them as
 * extern, which is essentially a placeholder until how built-in types are
 * fully worked out.
 */

import sylan.util.collections.tree as tree

class public Void
/**
 * The unit-type, a.k.a. `void`. It can be instantiated, but contains
 * nothing.
 */

enum public Boolean @derive(Equals, ToString) (
    public True,
    public False,
) {
    fun public extern operator && (other This)
    fun public extern operator || (other This)
    fun public extern negate()
}

class public True = Boolean True
class public False = Boolean False

fun public not(_ b Boolean) Boolean {
    b.negate
}

enum public Throws[_ Exception extends Exception: Exception, otherwise Result: Void](
    public Ok(Result)
    public Exception(Exception)
)

fun public ok[E extends Exception: Exception]() Throws[E, otherwise: Void] {
    Throws.Ok(Void)
}

fun final if
    /**
     * A hypothetical look at how `if` could be defined as a macro, creating
     * Sylan _from_ Kernel Sylan rather than translating _to_ Kernel Sylan in
     * Rust.
     *
     * This example is a bit silly because it assumes simplification steps like
     * applicative do-notation, pattern-matching, and `var` are already defined.
     */
(syntax pipeline Pipeline[from: CharReader, to: AstWriter]) Throws {

    var Pipeline(source, write) = pipeline

    // Trigger characters for read macros (and the trigger token for a
    // procedural macro) are available on `source.trigger` but are no longer
    // present in the source.

    // Explicit lexing triggers reader macros for characters consumed. They
    // aren't given another opportunity to trigger again in the generated
    // source.
    var lexer = Lexer(lexing: source)

    // Explicit parsing triggers procedural macros for tokens consumed. They
    // aren't given another opportunity to trigger again in the generated
    // source.
    //
    // Item macros can be both procudural and pattern, so the procedural kind
    // are also processed here.
    var parser = Parser(parsing: lexer)

    // At this point, only pattern macros remain unprocessed in the
    // generated source.

    with {
        var condition = parser.parseExpression()?
        var ifTrue = parser.parseScope()?
        parser.expectAndDiscard(tokens.Token.BranchingAndJumping(tokens.BranchingAndJumping.Else))?
        var ifFalse = parser.parseScope()?

        var ast = quote {
            switch unquote condition {
                True unquote ifTrue
                False unquote ifFalse
            }
        }
        write(ast)?
    }

    ok()
}

bind currentReadtable = currentReadtable.dispatchingOnChars(List('i', 'f'), readIf)
// Or just the `use` reader macro: `use("if", readIf)`
// Obviously the `use` macro itself can therefore not be initialised with `use`...

fun final kernelIf
    /**
     * Now, a second look at how this would look in Kernel Sylan. This is done
     * from a procedural macro rather than a reader one to keep the example
     * small.
     *
     * Even this assumes that lexical scoping is already defined though, but it
     * assumes that non-field `var`, pattern matching, and `with` do not yet
     * exist.
     *
     * `switch` is a special form, so it can be relied on here. The raw switch
     * doesn't do pattern matching or guards though.
     */
(syntax pipeline Pipeline[from: TokenReader, to: AstWriter]) Throws {
    -> source, write {
        -> parser {
            parser.parseExpression().flatMap(-> condition {
                parser.parseScope().flatMap(-> ifTrue {
                    parser.expectAndDiscard(tokens.Token.BranchingAndJumping(tokens.BranchingAndJumping.Else)).flatMap(-> _ {
                        parser.parseScope().flatMap(ifFalse -> {
                            write(quote {
                                switch unquote condition {
                                    True unquote ifTrue
                                    False unquote ifFalse
                                }
                            })
                        })
                    })
                })
            })
        }(Parser(parsing: source))
    }(pipeline.source, pipeline.dest)

    ok()
}

class public extern Invokable[Result, Args..]

extend class Invokable[Result, Args..] {

    fun public extern operator |> [T](other (Result) T) T
    fun public extern operator ~ [T](other (Result) T) (Args..) T
}

interface public Number {

    // Natively-defined arithmetic operators.
    fun public extern operator + (other This) This
    fun public extern operator - (other This) This
    fun public extern operator / (other This) This
    fun public extern operator % (other This) This
    fun public extern operator * (other This) This
    fun public extern operator ** (other This) This

    // Natively-defined bitwise operators.
    fun public extern operator & (other This) This
    fun public extern operator | (other This) This
    fun public extern operator ^ (other This) This

    fun public extern operator < (other This) This
    fun public extern operator <= (other This) This
    fun public extern operator == (other This) This
    fun public extern operator != (other This) This
    fun public extern operator > (other This) This
    fun public extern operator >= (other This) This

    fun public extern operator << (other This) This
    fun public extern operator >> (other This) This
    fun public extern operator >>> (other This) This

    fun public negate
        /**
         * Negate a number; replaces the unary minus operator present in other
         * languages.
         *
         * ```
         * assert(4.negate == (0 - 4))
         * ```
         */
    This {
        if 0 <= this {
            this - this.doubled
        } else {
            this
        }
    }

    fun public double This {
        this * 2
    }

    fun public triple This {
        this * 3
    }

    fun public quadruple This {
        this * 4
    }

    fun public quintuple This {
        this * 5
    }

    fun public up(to n This) List[of: This] {
        list.generate(initial: 1) -> {
            if n < it {
                list.generation.Finish
            } else {
                list.generation.Next(it, it + 1)
            }
        }
    }

    fun public twice() List[of: This] { up(to: 2) }
    fun public thrice() List[of: This] { up(to: 3) }
}

fun public extern bitnot[N extends Number](n N) N

// Built-in types, which look a bit like Java primitives except that they are
// real OO-style types. These can't be defined in Sylan itself due to their
// precise definition in raw memory.
class public extern Int
class public extern UInt
class public extern Byte
class public extern UInt16
class public extern UInt32
class public extern UInt64
class public extern Int8
class public extern Short
class public extern Int32
class public extern Long
class public extern Float
class public extern Double

class public extern Usize
/**
 * The maximum size of a contiguously allocated slab of memory. This is an
 * important concept in Sylan even outside of unsafe code, e.g. slice indices.
 */

fun final ignore
    /**
     * Useful for throwing away variables in contexts that are not already
     * explicitly void, such as enum instance initialisers and implicily-typed
     * lambdas. It works well with the pipe operator:
     *
     * add(40, 2) |> ignore
     */
[_ Item](_ Item) { }

fun final match[Item](_ item Item, syntax against pipeline AstPipline) Throws {
    var refuttablePattern = pipeline.source

    var ast = quote {
        switch unquote item {
            unquote refuttablePattern { True }
            _                         { False }
        }
    }
    pipeline.write(ast)
}


class public Ref
    /**
     * Sylan is an immutable language; data can't be modified. It's not _fully_
     * immutable though, due to its strong support for processes, or "tasks" as
     * Sylan calls them.
     * 
     * A task can hold its own state and recurse with differing data based
     * on incoming process messages, and sent out messages with state changes.
     * 
     * Therefore, a mutable memory address can be implemented by a task.
     * However, unlike a raw memory address, the updates are always atomic and
     * always update the _entire_ value in one go, not just _part_ of its memory
     * content.
     */
[to value Value] public (to value Value) {
    enum Msg(
        Get(dest Task: currentTask),
        Set(to newValue Value)
    )

    fun public get() Value            { sendAndWait(Msg.Get, to: task) }
    fun public set(to newValue Value) { send(Msg.Set(to: newValue), to: task) }

    var task = spawn -> {
        for var state = value {
            select Msg {
                Set(newValue) { continue(newValue) }
                Get(dest) {
                    send(state, to: dest)
                    continue(value)
                }
            }
        }
    }
}

//
// `AtomicallyMutable` used in `unsafe` is for performance sensitive areas where
// you don't mind dealing with low-level concurrency issues like atomicity,
// memory fences, etc. Unsafe Sylan code uses it, but most of the time, for safe
// code, the basic `Ref` above is all you need.
//

package unsafe
    /**
     * Placeholder definitions for now, to understand what needs to be exposed
     * to implement as much in Sylan as possible, such as `Vector` and garbage
     * collection.
     */
{
    // The maximum sizes of an addressable memory location. Not necessarily the
    // same as `Usize` on all architectures.
    class public extern UPtrInt
    class public extern PtrInt

    var rawNull UPtrInt = 0u.to[UptrInt]()

    class public extern Offset
    /** Double Usize and signed to allow offsetting in both directions. */

    class public extern DirectionalPtr
    /** Double UPtrUint and signed to allow arithmetic with `Offset`. */

    class public RawPtr public (var from raw UPtrInt, var byteCount Usize) {
        fun public extern init[T, Args..](args Args..)

        fun public extern realloc
            /** Copy C behaviour: if `null`, allocate freshly. */
        (newByteCount Usize) This

        fun public extern free()

        fun public extern load[_ T]() T
        fun public extern store[_ T](_ T)

        fun public offset(byBytes n Offset) This {
            var newRaw = (raw.to[DirectionalPtr] + n.to[DirectionalPtr]()).to[UPtrInt]
            This(from: newRaw)
        }
    }

    fun public extern rawAlloc
        /**
         * **Warning:** A `rawAlloc` followed by a `init` on a different OS thread
         * will lead to a lack of "publishing safety". The current task must be
         * pinned to the OS thread and must not allow the `RawPtr` to escape until
         * initialised with `init`.
         *
         * Alternatively, the task can avoid being pinned to the thread if the user
         * ensures no task yields happen between `alloc` and `init`.
         *
         * Lacking publishing safety means a read between `alloc` and `init` will
         * read uninitialised memory. Furthermore, leaking the pointer across task
         * threads could lead to uninitialised memory reads even after `init` has
         * run unless combined with a memory fence.
         */
    (byteCount Usize) RawPtr

    fun public extern final sizeInBytes[of T]() Usize

    var public nullPtr = RawPtr(from: 0, byteCount: 0)

    class public Ptr
        /**
         * Proposed usage style is like a mix of C and old-school Objective-C:
         *
         * ```
         * var item = alloc[Type]()
         * item.init(field1, field2)
         * free(item)
         * ```
         *
         * `AutoClosable` is implemented to make deallocating memory harder to
         * forget:
         *
         * ```
         * var item = using alloc[Type]()
         * item.init(field1, field2)
         * ``
         *
         * Use `new` to combine alloc and init in one step:
         *
         * ```
         * var item = using new[Type](field1, field2)
         * ```
         */
    [to: Item] public (var public from raw RawPtr) implements AutoClosable {

        fun public override close = delete

        fun public init = raw.init

        fun public realloc(newItemSize n Usize) This {
            raw.realloc(newByteSize: sizeInBytes[of: Item] * n)
        }

        fun public free = raw.free

        fun public extern load() Item { raw.load[Item]() }
        fun public extern store(item Item) { raw.store[Item](item)}

        fun public offset(byItems n Offset) This {
            This(from: raw.offset(sizeInBytes[of: Item] * n))
        }

        fun public incByItem() This {
            offset(byItems: 1.to[Offset]())
        }

        fun public decByItem() This {
            offset(byItems: -1.to[Offset]())
        }
    }

    fun public null[_ Item]() Ptr {
        Ptr[to: Item](from: nullPtr)
    }

    fun public alloc
        /**
         * **Warning:** An `alloc` followed by a `init` on a different OS
         * thread will lead to a lack of "publishing safety". The current task
         * must be pinned to the OS thread and must not allow the `Ptr` to
         * escape until initialised with `init`.
         *
         * Alternatively, the task can avoid being pinned to the thread if the
         * user ensures no task yields happen between `alloc` and `init`.
         *
         * Lacking publishing safety means a read between `alloc` and `init`
         * will read uninitialised memory. Furthermore, leaking the pointer
         * across task threads could lead to uninitialised memory reads even
         * after `init` has run unless combined with a memory fence.
         */
    [_ Item] public (itemCount Usize: 1) Ptr[to: Item] {
        alloc(byteCount: n * sizeInBytes[of: Item])
    }

    fun public new
       /**
         * Covers `new` from C++. There is no `delete` equivalent, only the
         * `free` method. As the naming indicates, there are no destructors in
         * Sylan.
         */
    [_ Item, with Arg..](initialisers Arg..) Ptr[to: Item] {
        var ptr = alloc(itemCount)
        ptr.init()
        ptr
    }

    fun public newContiguous
        /**
         * Covers `new[]` from C++. There is no `delete[]` equivalent, only the
         * `free` method. As the naming indicates, there are no destructors in
         * Sylan.
         */
    [of Item, with Arg..] public (itemCount Usize, initialisers Arg..) Ptr[to: Item] {
        var ptr = alloc(itemCount)

        for var i = 0, offsetPtr = ptr {
            if i == itemCount {
                ptr
            } else {
                offsetPtr.init(initialisers..)
                continue(i + 1, offsetPtr.incByItem())
            }
        }
    }

    package public mutation {
        package public atomic {
            
            class public AtomicallyMutable[_ Item extends AtomicMachineType](var _ item Item) {
                fun public extern load() Item
                fun public extern store(_ item Item)
            }
        }
    }
}

class public Vector
    /**
     * The only way to create homogenous, variably-sized collections in safe
     * Sylan, and a building block for other collection types.
     *
     * Vectors, unlike lists, are eagerly evaluated. They also are the types of
     * variadics.
     */
[of Item] public (of items Item..) {

    {
        items.each(push)
    }

    class AtomicallyMutable = unsafe.mutation.atomic.AtomicallyMutable

    var ptr AtomicallyMutable[unsafe.Ptr[to: Item]] = AtomicallyMutable[unsafe.null[Item]()]
    var size AtomicallyMutable[Usize] = AtomicallyMutable(0)

    fun public operator [||](index Usize) Optional[of: Item] {
        if size < index {
            None
        } else {
            var item = ptr.load().offset(byItems: index).load()
            Some(item)
        }
    }

    fun push(_ item Item)
        /**
         * Do not publish with `public`. It's not thread safe when combined with
         * operator `[||]`.
         */
    {
        var newSize = size.load() + 1
        var reallocated = ptr.load().realloc(byItems: newSize)
        var storeOffset = reallocated.offset(byItems: newSize - 1)
        storeOffset.store(item)
        ptr.store(reallocated)
    }
}

enum public List[of Item](
    public Nil,
    public Element(of item Item, next () This),
)(of items Item..) {

    {
        for var remaining = items {
            if var Some(element) = remaining[|0|] {
                Node.Element(of: element) -> {
                    remaining[|1 :]
                        |> continue
                }
            } else {
                Node.Nil
            }
        }
    }

    var public isEmpty Boolean = match(node, against: Nil)

    var public first Optional[of: Item] = switch node {
        Element(item, ..) { Some(item) }
        Nil               { Empty }
    }

    var public rest Optional[of: This] = switch node {
        Element(_, next) { Some(next) }
        Nil              { Empty }
    }
}

interface public ToString {
    fun public toString() String
}

interface public String {
    //
}

class public TaintedString implements String {
    //
}

class public EscapedString implements String {
    //
}

class public CompileTimeString implements String {
    //
}

class public Decimal {
    //
}

bind var collectGarbage Bool = true
bind var yieldTasks Bool = true
bind var checkNumericOverflow Bool = true
bind var checkVectorBounds Bool = true
bind var unlockUnsafePackage Bool = false
bind var allowNonStandardExtern Bool = false

bind var extern currentReadtable

interface LanguageReader[reading Item] {

    var fun trigger List[Item]

    fun public readMany
        /** Read from the reader, consuming them as they are returned. */
    (
        amount Usize
        /** The amount to attempt to read. */
    )
        Throws[otherwise: List[of: Item]]
        /**
         * What was read; if smaller than the amount, it means the reader hit
         * the end of its source. This means that the end of the source can be
         * detected by requesting more than zero to read and checking for an
         * empty resulting list.
         *
         * That is what [is_finished] does.
         */

    fun public peekMany
        /** Peek in the reader, multiple characters from an index. */
    (
        amount Usize,
        /** The amount to attempt to peek at.  */

        from index Usize: 0
        /** Whence to peek onwards. */
    )
        Throws[otherwise: List[of: Item]]
        /**
         * What was read; if smaller than the amount, it means the reader hit
         * the end of its source. This means that the end of the source can be
         * detected by requesting more than zero to peek at and checking for an
         * empty resulting list.
         *
         * That is what [is_finished] does.
         */

    fun public discard
    (
        amount Usize: 1
        /** The amount to attempt to discard. */
    )
        Throws[otherwise: Boolean]
        /**
         * Whether all `amount` items were discarded before encoutering the end
         * of the stream.
         */

    fun public read() Throws[otherwise: Optional[Item]] {
        readMany(amount: 1)
            .map(List.first)
    }

    fun public peek(at index: 0) Throws[otherwise: Optional[Item]] {
        peekMany(amount: 1, from: index)
            .map(List.first)
    }

    var fun public isFinished Throws[otherwise: Boolean] {
        peek.map(Optional.isEmpty)
    }

    fun public skipUntil
        /**
         * Consume and discard _until_ an item passes the match, so it's the
         * next item in the stream for the caller.
         */
    (matches (item Item) Boolean)
        Throws[otherwise: Boolean]
        /**
         * Whether the desired item was encountered before the end of the
         * stream.
         */
    {
        with {
            switch peek? {
                Some(.item) if matches(item) { Ok(True) }
                Some(_)                      { skip_until(matches) }
                Empty                        { Ok(False) }
            }
        }
    }

    fun public skip
        /**
         * Consume and discard _until_ the item, so it's the next item in the
         * stream for the caller.
         */
    (until item Item)
        Throws[otherwise: Boolean]
        /** Whether the desired item was encountered before the end of the stream. */
    {
        skip_until(matches: _ == item)
    }
}

interface public Ast {
    //
}

interface public ParameterAst extends Ast {
    //
}

interface public Token {
    //
}

enum public TokenTree
    /**
     * Tokens trees are just tokens that group together in the case of grouping
     * delimiters like `(`, `{`, and `[`.
     *
     * Sylan's own lexer and parser doesn't use these, they are solely for
     * procedural macros written in Sylan.
     */
(
    public Group(Token.Grouping),
    public Scalar(Token),
)

interface public ParameterLanguageReader[reading Item] extends LanguageReader[reading: Item] {
    fun public nextIsSubitemSeperator Throws[otherwise: Boolean]
    fun public nextIsCloseCall Throws[otherwise: Boolean]

    fun public resemblesEnd Throws[otherwise: Boolean] {
        with {
            (nextIsSubitemSeperator? || nextIsCloseCall?)
                |> Ok
        }
    }
}

interface public TokenReader extends LanguageReader[reading: TokenTree]

interface public ParameterTokenReader extends ParameterLanguageReader[reading: TokenTree] {
    var fun public nextIsSubitemSeperator Throws[otherwise: Boolean] {
        with {
            peek?
                .filter(_ == TokenTree.Scalar(Token.SubItemSeperator))
                .hasValue
                |> Ok
        }
    }

    var fun public nextIsCloseCall Throws[otherwise: Boolean] {
        with {
            peek?
                .filter(_ == (
                    tokens.Grouping.CloseParentheses
                    |> Token.Grouping
                    |> TokenTree.Group
                ))
                .hasValue
                |> Ok
        }
    }
}

interface public CharReader extends LanguageReader[reading: Char]

interface public ParameterCharReader extends ParameterLanguageReader[reading: Char] {

    var fun public nextIsSubitemSeperator Throws[otherwise: Boolean] {
        with {
            peek?
                .filter(_ == ',')
                .hasValue
                |> Ok
        }
    }

    var fun public nextIsCloseCall Throws[otherwise: Boolean] {
        with {
            peek?
                .filter(_ == ')')
                .hasValue
                |> Ok
        }
    }

    fun skipWhitespace
        /**
         * Consume and discard whitespace.
         * 
         * Unlike token reader macros, character reader macros don't get the
         * benefit of being able to ignore whitespace-handling. In fact, the
         * language they're defining might be whitespace-sensitive.
         *
         * This method should help.
         */
    () Throws {
        if skipUntil(matches: Character.isWhitespace ~ not) {
            with {
                discard?
                skipWhitespace?
            }
        }
    }
}

class LanguageWriter
    /**
     * Class aliases usually point to other classes. There is one exception:
     * function types can also be pointed to directly.
     */
    [writing Item] = (_ toWrite Item)

interface public CharWriter extends LanguageWriter[writing: Char]
interface public TokenWriter extends LanguageWriter[writing: TokenTree]
interface public AstWriter extends LanguageWriter[writing: Ast]

interface ReaderWriterPipeline[
    of Item,
    readingFrom Reader extends LanguageReader[reading: Item],
    writingTo Writer extends LanguageWriter[writing: Item],
] {
    var fun public source Reader
    var fun public write Writer

    fun public passthroughMany
        /** Pass items through from the source to the destination. */
    (
        amount USize: 1
        /** The amount to passthrough. */
    )
        Throws[otherwise: List[of: Item]]
        /**
         * What was passed through; if smaller than the amount, it means the
         * reader hit the end of its source.
         */
    {
        with {
            var items = source.read(amount)?
            items.each(-> item { write(item)? })
            items
        }
    }

    fun public passthrough() Throws[otherwise: Optional[Item]] {
        passthroughMany.map(List.first)
    }

    fun passthroughUntil
        /**
         * Many readers won't want to totally discard the whole previous language
         * (mostly likely Sylan itself for single-macro pipelines). They can let
         * most of the language pass through until it sees something it is interested
         * in changing.
         *
         * It skips _until_ an item passes the match, so it's the next item in the stream
         * for the caller.
         */
    (matches (item Item) Boolean)
        Throws[otherwise: Boolean]
        /** Whether the desired item was encountered before the end of the stream. */
    {
        with {
            switch passthrough? {
                Some(.item) if matches(item) { Ok(True) }
                Some(_)                      { passthroughUntil(matches) }
                Empty                        { Ok(False) }
            }
        }
    }

    fun passthroughUntilMatches
        /**
         * Many readers won't want to totally discard the whole previous language
         * (mostly likely Sylan itself for single-macro pipelines). They can let
         * most of the language pass through until it sees something it is interested
         * in changing.
         *
         * It skips _until_ the item, so it's the next item in the stream for the
         * caller.
         */
    (_ item Item)
        Throws[otherwise: Boolean]
        /** Whether the desired item was encountered before the end of the stream. */
    {
        passthroughUntil(matches: _ == item)
    }

    fun passthroughWhitespace
        /**
         * Many readers won't want to totally discard the whole previous language
         * (mostly likely Sylan itself for single-macro pipelines). They can let
         * most of the language pass through until it sees something it is
         * interested in changing.
         *
         * It skips _until_ non-whitespace, so it's the next item in the stream
         * for the caller.
         */
    (_ item Item)
        Throws[otherwise: Boolean]
        /** Whether the desired item was encountered before the end of the stream. */
    {
        passthroughUntil(matches: Character.isWhitespace ~ not)
    }
}

//
// The following types are used by macros.
//
// ASTs are the easiest to manipulate and the least error prone, but they're
// less powerful and can't be processed lazily and in parallel. They're ideal
// for simplification stages, changing evaluation strategies, creating magic
// identifiers such as anaphoric macros or auto-gensym, but not so much defining
// whole new languages.
//
// Token and character readers are powerful, able to produce any language, but
// also dangerous and unpredictable. Character readers grant the ability to
// define whitespace-sensitive languages.
//
// Unlike Sylan itself, which constrains itself to fixed lookahead to keep the
// language simple and comprehendible, reader and procedural macros can do
// unlimited lookahead with peek for both characters and tokens. Just because
// Sylan is sane enough to avoid unlimited lookahead doesn't mean other
// languages are.
//
// Normal consumers and parameter consumers are mostly the same, but gives the
// macro implementor the ability to change how their language is lexed or parsed
// depending on whether it was triggered by a macro call in another language or
// given a whole file. Parameter consumers also have some helper methods that
// don't make sense for file consumers, such as detecting the end of the
// parameter position that triggered it.
//
// These capabilities are quite "raw", but Sylan libraries can be created to
// raise the abstraction layer. There might be ParSec-style libraries,
// Yacc-style macros, or something else. Sylan is agnostic of the parsing
// strategy you use, providing the building blocks for your preferred approach.
//
// These types are the only valid types for `syntax` parameters. Based on
// which type a macro function defined will change how Sylan presents the
// syntax to that macro and unloads the result back into the destination
// language. A macro either supports file-level or parameter-level.
//
// If a macro wants to support both file- and parameter-level macros, it must
// provide two separate macros for each, otherwise the compiler will complain.
// Of course, one of them can just immediately delegate to the other if the
// sublanguage doesn't change its interpretation from being embedded versus
// being in its own file.
//

class public AstPipeline[Ast extends FileAst: FileAst]
    var public source Ast,
    var public write AstWriter,
)

class public Pipeline[
    of Item,
    readingFrom Source extends LanguageReader[of: Item]: LanguageReader[of: Item],
    writingTo Destination extends LanguageWriter[of: Item]: LanguageWriter[of: Item],
] implements ReaderWriterPipeline[
    of: Item,
    readingFrom: Source,
    writingTo: Destination,
(
    var public source Source,
    var public write Destination,
)

class public AsymmetricPipeline[from Source, to Destination](
    var public source Source,
    var public write Destination,
)

class public Task(var running task ()) {

    fun public extern start()
}

fun public spawn(running task ()) Task {
    var t = Task(running: task)
    t.start()
    t
}

fun public extern currentTask Task

fun public extern send[Item] Throws (_ item Item, to task Task)

fun public sendAndWait[sending Item, waitingFor Delivery: Item](
    sending item Item,
    to task Task
) Throws[otherwise: Delivery] {
    send(item, to: task)
        .map(-> _ { select Item })
}

class AssertionError implements Exception {

    var fun public override message String {
        "assertion failed"
    }
}

fun public final assert
    /**
     * Assert that predicate is true, otherwise throw an `AssertionError`.
     */
(syntax that AstPipeline(source, write) AstPipeline) Throws {

    // AST pipelines implement `ToString`. 
    //
    // DO NOT USE THIS TO GENERATE NEW SOURCE TO LEX OR PARSE. Generated ASTs
    // will not expect to trigger reader and procedural macros again, so that'll
    // break all sorts of assumptions of macro writers.
    // 
    // Only use it for converting source code to strings for debugging and
    // tooling purposes.
    var msg = $"Assertion failed: {source}"
    
    var ast = quote {
        if not(unquote source) {
            throw AssertionError(msg)
        }
    }
    write(ast)
}

fun public extern print(_ message String)

fun public println(_ message String) {
    print(message)
    print("\n")
}

fun public id[of T](of value T) T {
    value
}

fun public constant[of T](of value T) () T {
    -> {
        value
    }
}
